import { __asyncGenerator, __asyncValues, __await } from 'tslib';
import { trace, context, SpanKind } from '@opentelemetry/api';
import { InstrumentationBase, InstrumentationNodeModuleDefinition, safeExecuteInTheMiddle } from '@opentelemetry/instrumentation';
import { SpanAttributes, CONTEXT_KEY_ALLOW_TRACE_CONTENT } from '@traceloop/ai-semantic-conventions';
import { encodingForModel } from 'js-tiktoken';

var version = "0.13.0";

class OpenAIInstrumentation extends InstrumentationBase {
    constructor(config = {}) {
        super("@traceloop/instrumentation-openai", version, config);
        this._encodingCache = new Map();
    }
    setConfig(config = {}) {
        super.setConfig(config);
    }
    manuallyInstrument(module) {
        this._diag.debug(`Manually instrumenting openai`);
        // Old version of OpenAI API (v3.1.0)
        if (module.OpenAIApi) {
            this._wrap(module.OpenAIApi.prototype, "createChatCompletion", this.patchOpenAI("chat", "v3"));
            this._wrap(module.OpenAIApi.prototype, "createCompletion", this.patchOpenAI("completion", "v3"));
        }
        else {
            this._wrap(module.Chat.Completions.prototype, "create", this.patchOpenAI("chat"));
            this._wrap(module.Completions.prototype, "create", this.patchOpenAI("completion"));
        }
    }
    init() {
        const module = new InstrumentationNodeModuleDefinition("openai", [">=3.1.0 <5"], this.patch.bind(this), this.unpatch.bind(this));
        return module;
    }
    patch(moduleExports, moduleVersion) {
        this._diag.debug(`Patching openai@${moduleVersion}`);
        // Old version of OpenAI API (v3.1.0)
        if (moduleExports.OpenAIApi) {
            this._wrap(moduleExports.OpenAIApi.prototype, "createChatCompletion", this.patchOpenAI("chat", "v3"));
            this._wrap(moduleExports.OpenAIApi.prototype, "createCompletion", this.patchOpenAI("completion", "v3"));
        }
        else {
            this._wrap(moduleExports.OpenAI.Chat.Completions.prototype, "create", this.patchOpenAI("chat"));
            this._wrap(moduleExports.OpenAI.Completions.prototype, "create", this.patchOpenAI("completion"));
        }
        return moduleExports;
    }
    unpatch(moduleExports, moduleVersion) {
        this._diag.debug(`Unpatching openai@${moduleVersion}`);
        // Old version of OpenAI API (v3.1.0)
        if (moduleExports.OpenAIApi) {
            this._unwrap(moduleExports.OpenAIApi.prototype, "createChatCompletion");
            this._unwrap(moduleExports.OpenAIApi.prototype, "createCompletion");
        }
        else {
            this._unwrap(moduleExports.OpenAI.Chat.Completions.prototype, "create");
            this._unwrap(moduleExports.OpenAI.Completions.prototype, "create");
        }
    }
    patchOpenAI(type, version = "v4") {
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        const plugin = this;
        // eslint-disable-next-line
        return (original) => {
            return function method(...args) {
                const span = type === "chat"
                    ? plugin.startSpan({
                        type,
                        params: args[0],
                    })
                    : plugin.startSpan({
                        type,
                        params: args[0],
                    });
                const execContext = trace.setSpan(context.active(), span);
                const execPromise = safeExecuteInTheMiddle(() => {
                    return context.with(execContext, () => {
                        var _a;
                        if ((_a = args === null || args === void 0 ? void 0 : args[0]) === null || _a === void 0 ? void 0 : _a.extraAttributes) {
                            delete args[0].extraAttributes;
                        }
                        return original.apply(this, args);
                    });
                }, (e) => {
                    if (e) {
                        plugin._diag.error("OpenAI instrumentation: error", e);
                    }
                });
                if (args[0].stream) {
                    return context.bind(execContext, plugin._streamingWrapPromise({
                        span,
                        type,
                        params: args[0],
                        promise: execPromise,
                    }));
                }
                const wrappedPromise = plugin._wrapPromise(type, version, span, execPromise);
                return context.bind(execContext, wrappedPromise);
            };
        };
    }
    startSpan({ type, params, }) {
        var _a, _b, _c, _d;
        const attributes = {
            [SpanAttributes.LLM_SYSTEM]: "OpenAI",
            [SpanAttributes.LLM_REQUEST_TYPE]: type,
        };
        try {
            attributes[SpanAttributes.LLM_REQUEST_MODEL] = params.model;
            if (params.max_tokens) {
                attributes[SpanAttributes.LLM_REQUEST_MAX_TOKENS] = params.max_tokens;
            }
            if (params.temperature) {
                attributes[SpanAttributes.LLM_REQUEST_TEMPERATURE] = params.temperature;
            }
            if (params.top_p) {
                attributes[SpanAttributes.LLM_REQUEST_TOP_P] = params.top_p;
            }
            if (params.frequency_penalty) {
                attributes[SpanAttributes.LLM_FREQUENCY_PENALTY] =
                    params.frequency_penalty;
            }
            if (params.presence_penalty) {
                attributes[SpanAttributes.LLM_PRESENCE_PENALTY] =
                    params.presence_penalty;
            }
            if (params.extraAttributes !== undefined &&
                typeof params.extraAttributes === "object") {
                Object.keys(params.extraAttributes).forEach((key) => {
                    attributes[key] = params.extraAttributes[key];
                });
            }
            if (this._shouldSendPrompts()) {
                if (type === "chat") {
                    params.messages.forEach((message, index) => {
                        attributes[`${SpanAttributes.LLM_PROMPTS}.${index}.role`] =
                            message.role;
                        if (typeof message.content === "string") {
                            attributes[`${SpanAttributes.LLM_PROMPTS}.${index}.content`] =
                                message.content || "";
                        }
                        else {
                            attributes[`${SpanAttributes.LLM_PROMPTS}.${index}.content`] =
                                JSON.stringify(message.content);
                        }
                    });
                    (_a = params.functions) === null || _a === void 0 ? void 0 : _a.forEach((func, index) => {
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.name`] = func.name;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.description`] = func.description;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.arguments`] = JSON.stringify(func.parameters);
                    });
                    (_b = params.tools) === null || _b === void 0 ? void 0 : _b.forEach((tool, index) => {
                        if (!tool.function) {
                            return;
                        }
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.name`] = tool.function.name;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.description`] = tool.function.description;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.arguments`] = JSON.stringify(tool.function.parameters);
                    });
                }
                else {
                    attributes[`${SpanAttributes.LLM_PROMPTS}.0.role`] = "user";
                    if (typeof params.prompt === "string") {
                        attributes[`${SpanAttributes.LLM_PROMPTS}.0.content`] =
                            params.prompt;
                    }
                    else {
                        attributes[`${SpanAttributes.LLM_PROMPTS}.0.content`] =
                            JSON.stringify(params.prompt);
                    }
                }
            }
        }
        catch (e) {
            this._diag.debug(e);
            (_d = (_c = this._config).exceptionLogger) === null || _d === void 0 ? void 0 : _d.call(_c, e);
        }
        return this.tracer.startSpan(`openai.${type}`, {
            kind: SpanKind.CLIENT,
            attributes,
        });
    }
    _streamingWrapPromise(_a) {
        return __asyncGenerator(this, arguments, function* _streamingWrapPromise_1({ span, type, params, promise, }) {
            var _b, e_1, _c, _d, _e, e_2, _f, _g;
            var _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0, _1, _2, _3, _4, _5, _6, _7, _8;
            if (type === "chat") {
                const result = {
                    id: "0",
                    created: -1,
                    model: "",
                    choices: [
                        {
                            index: 0,
                            logprobs: null,
                            finish_reason: "stop",
                            message: {
                                role: "assistant",
                                content: "",
                                refusal: null,
                                tool_calls: [],
                            },
                        },
                    ],
                    object: "chat.completion",
                };
                try {
                    for (var _9 = true, _10 = __asyncValues(yield __await(promise)), _11; _11 = yield __await(_10.next()), _b = _11.done, !_b; _9 = true) {
                        _d = _11.value;
                        _9 = false;
                        const chunk = _d;
                        yield yield __await(chunk);
                        result.id = chunk.id;
                        result.created = chunk.created;
                        result.model = chunk.model;
                        if ((_h = chunk.choices[0]) === null || _h === void 0 ? void 0 : _h.finish_reason) {
                            result.choices[0].finish_reason = chunk.choices[0].finish_reason;
                        }
                        if ((_j = chunk.choices[0]) === null || _j === void 0 ? void 0 : _j.logprobs) {
                            result.choices[0].logprobs = chunk.choices[0].logprobs;
                        }
                        if ((_k = chunk.choices[0]) === null || _k === void 0 ? void 0 : _k.delta.content) {
                            result.choices[0].message.content += chunk.choices[0].delta.content;
                        }
                        if (((_l = chunk.choices[0]) === null || _l === void 0 ? void 0 : _l.delta.function_call) &&
                            ((_m = chunk.choices[0]) === null || _m === void 0 ? void 0 : _m.delta.function_call.arguments) &&
                            ((_o = chunk.choices[0]) === null || _o === void 0 ? void 0 : _o.delta.function_call.name)) {
                            // I needed to re-build the object so that Typescript will understand that `name` and `argument` are not null.
                            result.choices[0].message.function_call = {
                                name: chunk.choices[0].delta.function_call.name,
                                arguments: chunk.choices[0].delta.function_call.arguments,
                            };
                        }
                        for (const toolCall of (_r = (_q = (_p = chunk.choices[0]) === null || _p === void 0 ? void 0 : _p.delta) === null || _q === void 0 ? void 0 : _q.tool_calls) !== null && _r !== void 0 ? _r : []) {
                            if (((_t = (_s = result.choices[0].message.tool_calls) === null || _s === void 0 ? void 0 : _s.length) !== null && _t !== void 0 ? _t : 0) <
                                toolCall.index + 1) {
                                (_u = result.choices[0].message.tool_calls) === null || _u === void 0 ? void 0 : _u.push({
                                    function: {
                                        name: "",
                                        arguments: "",
                                    },
                                    id: "",
                                    type: "function",
                                });
                            }
                            if (result.choices[0].message.tool_calls) {
                                if (toolCall.id) {
                                    result.choices[0].message.tool_calls[toolCall.index].id +=
                                        toolCall.id;
                                }
                                if (toolCall.type) {
                                    result.choices[0].message.tool_calls[toolCall.index].type +=
                                        toolCall.type;
                                }
                                if ((_v = toolCall.function) === null || _v === void 0 ? void 0 : _v.name) {
                                    result.choices[0].message.tool_calls[toolCall.index].function.name += toolCall.function.name;
                                }
                                if ((_w = toolCall.function) === null || _w === void 0 ? void 0 : _w.arguments) {
                                    result.choices[0].message.tool_calls[toolCall.index].function.arguments += toolCall.function.arguments;
                                }
                            }
                        }
                    }
                }
                catch (e_1_1) { e_1 = { error: e_1_1 }; }
                finally {
                    try {
                        if (!_9 && !_b && (_c = _10.return)) yield __await(_c.call(_10));
                    }
                    finally { if (e_1) throw e_1.error; }
                }
                if ((_x = result.choices[0].logprobs) === null || _x === void 0 ? void 0 : _x.content) {
                    this._addLogProbsEvent(span, result.choices[0].logprobs);
                }
                if (this._config.enrichTokens) {
                    let promptTokens = 0;
                    for (const message of params.messages) {
                        promptTokens +=
                            (_y = this.tokenCountFromString(message.content, result.model)) !== null && _y !== void 0 ? _y : 0;
                    }
                    const completionTokens = this.tokenCountFromString((_z = result.choices[0].message.content) !== null && _z !== void 0 ? _z : "", result.model);
                    if (completionTokens) {
                        result.usage = {
                            prompt_tokens: promptTokens,
                            completion_tokens: completionTokens,
                            total_tokens: promptTokens + completionTokens,
                        };
                    }
                }
                this._endSpan({ span, type, result });
            }
            else {
                const result = {
                    id: "0",
                    created: -1,
                    model: "",
                    choices: [
                        {
                            index: 0,
                            logprobs: null,
                            finish_reason: "stop",
                            text: "",
                        },
                    ],
                    object: "text_completion",
                };
                try {
                    for (var _12 = true, _13 = __asyncValues(yield __await(promise)), _14; _14 = yield __await(_13.next()), _e = _14.done, !_e; _12 = true) {
                        _g = _14.value;
                        _12 = false;
                        const chunk = _g;
                        yield yield __await(chunk);
                        try {
                            result.id = chunk.id;
                            result.created = chunk.created;
                            result.model = chunk.model;
                            if ((_0 = chunk.choices[0]) === null || _0 === void 0 ? void 0 : _0.finish_reason) {
                                result.choices[0].finish_reason = chunk.choices[0].finish_reason;
                            }
                            if ((_1 = chunk.choices[0]) === null || _1 === void 0 ? void 0 : _1.logprobs) {
                                result.choices[0].logprobs = chunk.choices[0].logprobs;
                            }
                            if ((_2 = chunk.choices[0]) === null || _2 === void 0 ? void 0 : _2.text) {
                                result.choices[0].text += chunk.choices[0].text;
                            }
                        }
                        catch (e) {
                            this._diag.debug(e);
                            (_4 = (_3 = this._config).exceptionLogger) === null || _4 === void 0 ? void 0 : _4.call(_3, e);
                        }
                    }
                }
                catch (e_2_1) { e_2 = { error: e_2_1 }; }
                finally {
                    try {
                        if (!_12 && !_e && (_f = _13.return)) yield __await(_f.call(_13));
                    }
                    finally { if (e_2) throw e_2.error; }
                }
                try {
                    if (result.choices[0].logprobs) {
                        this._addLogProbsEvent(span, result.choices[0].logprobs);
                    }
                    if (this._config.enrichTokens) {
                        const promptTokens = (_5 = this.tokenCountFromString(params.prompt, result.model)) !== null && _5 !== void 0 ? _5 : 0;
                        const completionTokens = this.tokenCountFromString((_6 = result.choices[0].text) !== null && _6 !== void 0 ? _6 : "", result.model);
                        if (completionTokens) {
                            result.usage = {
                                prompt_tokens: promptTokens,
                                completion_tokens: completionTokens,
                                total_tokens: promptTokens + completionTokens,
                            };
                        }
                    }
                }
                catch (e) {
                    this._diag.debug(e);
                    (_8 = (_7 = this._config).exceptionLogger) === null || _8 === void 0 ? void 0 : _8.call(_7, e);
                }
                this._endSpan({ span, type, result });
            }
        });
    }
    _wrapPromise(type, version, span, promise) {
        return promise._thenUnwrap((result) => {
            if (version === "v3") {
                if (type === "chat") {
                    this._addLogProbsEvent(span, result.data.choices[0].logprobs);
                    this._endSpan({
                        type,
                        span,
                        result: result.data,
                    });
                }
                else {
                    this._addLogProbsEvent(span, result.data.choices[0].logprobs);
                    this._endSpan({
                        type,
                        span,
                        result: result.data,
                    });
                }
            }
            else {
                if (type === "chat") {
                    this._addLogProbsEvent(span, result.choices[0].logprobs);
                    this._endSpan({ type, span, result: result });
                }
                else {
                    this._addLogProbsEvent(span, result.choices[0].logprobs);
                    this._endSpan({ type, span, result: result });
                }
            }
            return result;
        });
    }
    _endSpan({ span, type, result, }) {
        var _a, _b, _c, _d, _e;
        try {
            span.setAttribute(SpanAttributes.LLM_RESPONSE_MODEL, result.model);
            if (result.usage) {
                span.setAttribute(SpanAttributes.LLM_USAGE_TOTAL_TOKENS, (_a = result.usage) === null || _a === void 0 ? void 0 : _a.total_tokens);
                span.setAttribute(SpanAttributes.LLM_USAGE_COMPLETION_TOKENS, (_b = result.usage) === null || _b === void 0 ? void 0 : _b.completion_tokens);
                span.setAttribute(SpanAttributes.LLM_USAGE_PROMPT_TOKENS, (_c = result.usage) === null || _c === void 0 ? void 0 : _c.prompt_tokens);
            }
            if (this._shouldSendPrompts()) {
                if (type === "chat") {
                    result.choices.forEach((choice, index) => {
                        var _a, _b, _c;
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.finish_reason`, choice.finish_reason);
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.role`, choice.message.role);
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.content`, (_a = choice.message.content) !== null && _a !== void 0 ? _a : "");
                        if (choice.message.function_call) {
                            span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.function_call.name`, choice.message.function_call.name);
                            span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.function_call.arguments`, choice.message.function_call.arguments);
                        }
                        for (const [toolIndex, toolCall,] of ((_c = (_b = choice === null || choice === void 0 ? void 0 : choice.message) === null || _b === void 0 ? void 0 : _b.tool_calls) === null || _c === void 0 ? void 0 : _c.entries()) || []) {
                            span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.tool_calls.${toolIndex}.name`, toolCall.function.name);
                            span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.tool_calls.${toolIndex}.arguments`, toolCall.function.arguments);
                        }
                    });
                }
                else {
                    result.choices.forEach((choice, index) => {
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.finish_reason`, choice.finish_reason);
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.role`, "assistant");
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.content`, choice.text);
                    });
                }
            }
        }
        catch (e) {
            this._diag.debug(e);
            (_e = (_d = this._config).exceptionLogger) === null || _e === void 0 ? void 0 : _e.call(_d, e);
        }
        span.end();
    }
    _shouldSendPrompts() {
        const contextShouldSendPrompts = context
            .active()
            .getValue(CONTEXT_KEY_ALLOW_TRACE_CONTENT);
        if (contextShouldSendPrompts !== undefined) {
            return contextShouldSendPrompts;
        }
        return this._config.traceContent !== undefined
            ? this._config.traceContent
            : true;
    }
    _addLogProbsEvent(span, logprobs) {
        var _a, _b;
        try {
            let result = [];
            if (!logprobs) {
                return;
            }
            const chatLogprobs = logprobs;
            const completionLogprobs = logprobs;
            if (chatLogprobs.content) {
                result = chatLogprobs.content.map((logprob) => {
                    return {
                        token: logprob.token,
                        logprob: logprob.logprob,
                    };
                });
            }
            else if ((completionLogprobs === null || completionLogprobs === void 0 ? void 0 : completionLogprobs.tokens) &&
                (completionLogprobs === null || completionLogprobs === void 0 ? void 0 : completionLogprobs.token_logprobs)) {
                completionLogprobs.tokens.forEach((token, index) => {
                    var _a;
                    const logprob = (_a = completionLogprobs.token_logprobs) === null || _a === void 0 ? void 0 : _a.at(index);
                    if (logprob) {
                        result.push({
                            token,
                            logprob,
                        });
                    }
                });
            }
            span.addEvent("logprobs", { logprobs: JSON.stringify(result) });
        }
        catch (e) {
            this._diag.debug(e);
            (_b = (_a = this._config).exceptionLogger) === null || _b === void 0 ? void 0 : _b.call(_a, e);
        }
    }
    tokenCountFromString(text, model) {
        var _a, _b;
        if (!text) {
            return 0;
        }
        let encoding = this._encodingCache.get(model);
        if (!encoding) {
            try {
                encoding = encodingForModel(model);
                this._encodingCache.set(model, encoding);
            }
            catch (e) {
                this._diag.debug(e);
                (_b = (_a = this._config).exceptionLogger) === null || _b === void 0 ? void 0 : _b.call(_a, e);
                return 0;
            }
        }
        return encoding.encode(text).length;
    }
}

export { OpenAIInstrumentation };
//# sourceMappingURL=index.mjs.map
