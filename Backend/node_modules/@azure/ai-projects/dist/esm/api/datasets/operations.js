// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/* eslint-disable tsdoc/syntax */
import * as fs from "fs";
import * as nodePath from "path";
import { _pagedDatasetVersionDeserializer, datasetVersionUnionSerializer, datasetVersionUnionDeserializer, pendingUploadRequestSerializer, pendingUploadResponseDeserializer, assetCredentialResponseDeserializer, } from "../../models/models.js";
import { expandUrlTemplate } from "../../static-helpers/urlTemplate.js";
import { buildPagedAsyncIterator, } from "../../static-helpers/pagingHelpers.js";
import { createRestError, operationOptionsToRequestParameters, } from "@azure-rest/core-client";
import { ContainerClient } from "@azure/storage-blob";
export function _getCredentialsSend(context, name, version, options = { requestOptions: {} }) {
    var _a, _b;
    const path = expandUrlTemplate("/datasets/{name}/versions/{version}/credentials{?api-version}", {
        name: name,
        version: version,
        "api-version": context.apiVersion,
    }, {
        allowReserved: (_a = options === null || options === void 0 ? void 0 : options.requestOptions) === null || _a === void 0 ? void 0 : _a.skipUrlEncoding,
    });
    return context.path(path).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { headers: Object.assign({ accept: "application/json" }, (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.headers) }));
}
export async function _getCredentialsDeserialize(result) {
    const expectedStatuses = ["200"];
    if (!expectedStatuses.includes(result.status)) {
        throw createRestError(result);
    }
    return assetCredentialResponseDeserializer(result.body);
}
/** Get the SAS credential to access the storage account associated with a Dataset version. */
export async function getCredentials(context, name, version, options = { requestOptions: {} }) {
    const result = await _getCredentialsSend(context, name, version, options);
    return _getCredentialsDeserialize(result);
}
export function _pendingUploadSend(context, name, version, body, options = { requestOptions: {} }) {
    var _a, _b;
    const path = expandUrlTemplate("/datasets/{name}/versions/{version}/startPendingUpload{?api-version}", {
        name: name,
        version: version,
        "api-version": context.apiVersion,
    }, {
        allowReserved: (_a = options === null || options === void 0 ? void 0 : options.requestOptions) === null || _a === void 0 ? void 0 : _a.skipUrlEncoding,
    });
    return context.path(path).post(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { contentType: "application/json", headers: Object.assign({ accept: "application/json" }, (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.headers), body: pendingUploadRequestSerializer(body) }));
}
export async function _pendingUploadDeserialize(result) {
    const expectedStatuses = ["200"];
    if (!expectedStatuses.includes(result.status)) {
        throw createRestError(result);
    }
    return pendingUploadResponseDeserializer(result.body);
}
/** Start a new or get an existing pending upload of a dataset for a specific version. */
export async function pendingUpload(context, name, version, body, options = { requestOptions: {} }) {
    const result = await _pendingUploadSend(context, name, version, body, options);
    return _pendingUploadDeserialize(result);
}
// Internal helper method to create a new dataset and return a ContainerClient from azure-storage-blob package, to the dataset's blob storage.
async function createDatasetAndGetItsContainer(context, name, version, 
// Optional connection name for the storage account to be used
connectionName) {
    var _a;
    // Start a pending upload to get the container URL with SAS token
    const pendingUploadResponse = await pendingUpload(context, name, version, {
        pendingUploadType: "BlobReference",
        connectionName,
    });
    const blobReference = pendingUploadResponse.blobReference;
    // Validate the response
    if (!blobReference) {
        throw new Error("Blob reference for consumption is not present");
    }
    if (!((_a = blobReference.credential) === null || _a === void 0 ? void 0 : _a.type)) {
        throw new Error("Credential type is not present");
    }
    if (blobReference.credential.type !== "SAS") {
        throw new Error("Credential type is not SAS");
    }
    if (!blobReference.blobUri) {
        throw new Error("Blob URI is not present or empty");
    }
    // Optional debug logging
    console.debug(`[createDatasetAndGetItsContainer] pendingUploadResponse.pendingUploadId = ${pendingUploadResponse.pendingUploadId}`);
    console.debug(`[createDatasetAndGetItsContainer] pendingUploadResponse.pendingUploadType = ${pendingUploadResponse.pendingUploadType}`);
    console.debug(`[createDatasetAndGetItsContainer] blobReference.blobUri = ${blobReference.blobUri}`);
    console.debug(`[createDatasetAndGetItsContainer] blobReference.storageAccountArmId = ${blobReference.storageAccountArmId}`);
    console.debug(`[createDatasetAndGetItsContainer] blobReference.credential.sasUri = ${blobReference.credential.sasUri}`);
    console.debug(`[createDatasetAndGetItsContainer] blobReference.credential.type = ${blobReference.credential.type}`);
    // Create container client from the blob URI (which includes the SAS token)
    const containerClient = new ContainerClient(blobReference.credential.sasUri);
    return {
        containerClient,
        version,
    };
}
export async function uploadFile(context, name, version, filePath, connectionName) {
    // if file does not exist
    const fileExists = fs.existsSync(filePath);
    if (!fileExists) {
        throw new Error(`File does not exist at path: ${filePath}`);
    }
    // Check if the file is a directory
    const isDirectory = fs.lstatSync(filePath).isDirectory();
    if (isDirectory) {
        throw new Error(`The provided file is actually a folder. Use method uploadFolder instead`);
    }
    const { containerClient, version: outputVersion } = await createDatasetAndGetItsContainer(context, name, version, connectionName);
    // file name as blob name
    const blobName = nodePath.basename(filePath);
    const blockBlobClient = containerClient.getBlockBlobClient(blobName);
    await blockBlobClient.uploadStream(fs.createReadStream(filePath));
    const datasetVersion = await createOrUpdate(context, name, outputVersion, {
        name: name,
        version: outputVersion,
        type: "uri_file",
        dataUri: blockBlobClient.url,
    });
    return datasetVersion;
}
export async function uploadFolder(context, name, version, folderPath, connectionName) {
    // Check if the folder exists
    const folderExists = fs.existsSync(folderPath);
    if (!folderExists) {
        throw new Error(`Folder does not exist at path: ${folderPath}`);
    }
    // Check if the folder is a file
    const isFile = fs.lstatSync(folderPath).isFile();
    if (isFile) {
        throw new Error(`The provided path is actually a file. Use method uploadFile instead`);
    }
    const { containerClient, version: outputVersion } = await createDatasetAndGetItsContainer(context, name, version, connectionName);
    // Helper function to recursively get all files in a directory
    async function getAllFiles(dir, fileList = []) {
        const files = await fs.promises.readdir(dir);
        for (const file of files) {
            const filePath = `${dir}/${file}`;
            const stat = await fs.promises.lstat(filePath);
            if (stat.isDirectory()) {
                await getAllFiles(filePath, fileList);
            }
            else {
                fileList.push(filePath);
            }
        }
        return fileList;
    }
    // Get all files in the folder
    const allFiles = await getAllFiles(folderPath);
    if (allFiles.length === 0) {
        throw new Error("The provided folder is empty.");
    }
    // Upload each file to blob storage while maintaining relative paths
    for (const filePath of allFiles) {
        // Create blob name as relative path from the base folder
        const relativePath = nodePath.relative(folderPath, filePath).split(nodePath.sep).join("/");
        console.debug(`[uploadFolderAndCreate] Start uploading file '${filePath}' as blob '${relativePath}'`);
        // Get a block blob client for the relative path
        const blobClient = containerClient.getBlockBlobClient(relativePath);
        // Upload the file using a readable stream for better performance
        const fileStream = fs.createReadStream(filePath);
        await blobClient.uploadStream(fileStream);
        console.debug(`[uploadFolderAndCreate] Done uploading file '${filePath}' as blob '${relativePath}'`);
    }
    // Create dataset version that references this folder
    const datasetVersion = await createOrUpdate(context, name, outputVersion, {
        name: name,
        version: outputVersion,
        type: "uri_folder",
        dataUri: containerClient.url,
    });
    return datasetVersion;
}
export function _createOrUpdateSend(context, name, version, body, options = { requestOptions: {} }) {
    var _a, _b;
    const path = expandUrlTemplate("/datasets/{name}/versions/{version}{?api-version}", {
        name: name,
        version: version,
        "api-version": context.apiVersion,
    }, {
        allowReserved: (_a = options === null || options === void 0 ? void 0 : options.requestOptions) === null || _a === void 0 ? void 0 : _a.skipUrlEncoding,
    });
    return context.path(path).patch(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { contentType: "application/merge-patch+json", headers: Object.assign({ accept: "application/json" }, (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.headers), body: datasetVersionUnionSerializer(body) }));
}
export async function _createOrUpdateDeserialize(result) {
    const expectedStatuses = ["201", "200"];
    if (!expectedStatuses.includes(result.status)) {
        throw createRestError(result);
    }
    return datasetVersionUnionDeserializer(result.body);
}
/** Create a new or update an existing DatasetVersion with the given version id */
export async function createOrUpdate(context, name, version, body, options = { requestOptions: {} }) {
    const result = await _createOrUpdateSend(context, name, version, body, options);
    return _createOrUpdateDeserialize(result);
}
export function _$deleteSend(context, name, version, options = { requestOptions: {} }) {
    var _a, _b;
    const path = expandUrlTemplate("/datasets/{name}/versions/{version}{?api-version}", {
        name: name,
        version: version,
        "api-version": context.apiVersion,
    }, {
        allowReserved: (_a = options === null || options === void 0 ? void 0 : options.requestOptions) === null || _a === void 0 ? void 0 : _a.skipUrlEncoding,
    });
    return context.path(path).delete(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { headers: Object.assign({ accept: "application/json" }, (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.headers) }));
}
export async function _$deleteDeserialize(result) {
    const expectedStatuses = ["204"];
    if (!expectedStatuses.includes(result.status)) {
        throw createRestError(result);
    }
    return;
}
/** Delete the specific version of the DatasetVersion */
/**
 *  @fixme delete is a reserved word that cannot be used as an operation name.
 *         Please add @clientName("clientName") or @clientName("<JS-Specific-Name>", "javascript")
 *         to the operation to override the generated name.
 */
export async function $delete(context, name, version, options = { requestOptions: {} }) {
    const result = await _$deleteSend(context, name, version, options);
    return _$deleteDeserialize(result);
}
export function _getSend(context, name, version, options = { requestOptions: {} }) {
    var _a, _b;
    const path = expandUrlTemplate("/datasets/{name}/versions/{version}{?api-version}", {
        name: name,
        version: version,
        "api-version": context.apiVersion,
    }, {
        allowReserved: (_a = options === null || options === void 0 ? void 0 : options.requestOptions) === null || _a === void 0 ? void 0 : _a.skipUrlEncoding,
    });
    return context.path(path).get(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { headers: Object.assign({ accept: "application/json" }, (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.headers) }));
}
export async function _getDeserialize(result) {
    const expectedStatuses = ["200"];
    if (!expectedStatuses.includes(result.status)) {
        throw createRestError(result);
    }
    return datasetVersionUnionDeserializer(result.body);
}
/** Get the specific version of the DatasetVersion */
export async function get(context, name, version, options = { requestOptions: {} }) {
    const result = await _getSend(context, name, version, options);
    return _getDeserialize(result);
}
export function _listSend(context, options = { requestOptions: {} }) {
    var _a, _b;
    const path = expandUrlTemplate("/datasets{?api-version}", {
        "api-version": context.apiVersion,
    }, {
        allowReserved: (_a = options === null || options === void 0 ? void 0 : options.requestOptions) === null || _a === void 0 ? void 0 : _a.skipUrlEncoding,
    });
    return context.path(path).get(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { headers: Object.assign({ accept: "application/json" }, (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.headers) }));
}
export async function _listDeserialize(result) {
    const expectedStatuses = ["200"];
    if (!expectedStatuses.includes(result.status)) {
        throw createRestError(result);
    }
    return _pagedDatasetVersionDeserializer(result.body);
}
/** List the latest version of each DatasetVersion */
export function list(context, options = { requestOptions: {} }) {
    return buildPagedAsyncIterator(context, () => _listSend(context, options), _listDeserialize, ["200"], { itemName: "value", nextLinkName: "nextLink" });
}
export function _listVersionsSend(context, name, options = { requestOptions: {} }) {
    var _a, _b;
    const path = expandUrlTemplate("/datasets/{name}/versions{?api-version}", {
        name: name,
        "api-version": context.apiVersion,
    }, {
        allowReserved: (_a = options === null || options === void 0 ? void 0 : options.requestOptions) === null || _a === void 0 ? void 0 : _a.skipUrlEncoding,
    });
    return context.path(path).get(Object.assign(Object.assign({}, operationOptionsToRequestParameters(options)), { headers: Object.assign({ accept: "application/json" }, (_b = options.requestOptions) === null || _b === void 0 ? void 0 : _b.headers) }));
}
export async function _listVersionsDeserialize(result) {
    const expectedStatuses = ["200"];
    if (!expectedStatuses.includes(result.status)) {
        throw createRestError(result);
    }
    return _pagedDatasetVersionDeserializer(result.body);
}
/** List all versions of the given DatasetVersion */
export function listVersions(context, name, options = { requestOptions: {} }) {
    return buildPagedAsyncIterator(context, () => _listVersionsSend(context, name, options), _listVersionsDeserialize, ["200"], { itemName: "value", nextLinkName: "nextLink" });
}
//# sourceMappingURL=operations.js.map