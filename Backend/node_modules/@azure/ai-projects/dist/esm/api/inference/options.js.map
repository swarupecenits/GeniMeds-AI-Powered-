{"version":3,"file":"options.js","sourceRoot":"","sources":["../../../../src/api/inference/options.ts"],"names":[],"mappings":"AAAA,uCAAuC;AACvC,kCAAkC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT License.\n\nimport type {\n  ConnectionsGetOptionalParams,\n  ConnectionsGetWithCredentialsOptionalParams,\n} from \"../connections/options.js\";\n\n/** The options for configuring the Azure OpenAI client. */\nexport interface AzureOpenAIClientOptions {\n  /**\n   * The Azure OpenAI api-version to use when creating the client.\n   *  See \"Data plane - Inference\" row in the table at\n   *  https://learn.microsoft.com/azure/ai-services/openai/reference#api-specs. If not provided,\n   *  you must set the environment variable `OPENAI_API_VERSION` instead.\n   */\n  apiVersion?: string;\n  /**  The name of a connection to an Azure OpenAI resource in your AI Foundry project. If not provided, the default Azure OpenAI connection will be used. */\n  connectionName?: string;\n  /** The connection options to use for the Azure OpenAI connection. */\n  connectionOptions?: ConnectionsGetOptionalParams;\n  /** The connection secret options to use for the Azure OpenAI client. */\n  connectionSecretOptions?: ConnectionsGetWithCredentialsOptionalParams;\n}\n"]}